---
date: 2026-02-12T12:00:00+08:00
title: Computer Architecture
draft: false
# bookFlatSection: false        # 是否显示扁平章节（默认false）
# bookToc: true                 # 是否显示目录（默认true）
# bookHidden: false             # 是否在侧边栏列表中隐藏（默认false）
# bookCollapseSection: false    # 章节是否默认折叠（默认false）
# bookComments: false           # 是否启用评论（默认false）
# bookSearchExclude: false      # 是否从搜索结果中排除（默认false）
# params:                       # 自定义参数
#   maths: true                 # 数学公式支持
# weight: 1                     # 内容权重（排序用）
---

# 计算机体系结构

计算机体系结构课有两种基本的教学方法：一种被称作自底向上（bottom-up），另一种则是自顶向下（top-down）。

自底向上方法从入门开始介绍，然后是电路、系统，最后是计算机。每个新的层次都构建在之前的教学内容上，学生之所以能够理解一台计算机是如何巩固走的，是因为他已经了解了每个部件的工作原理。这种教学方法的问题在于学生不了解最终的设计目标，同时也有可能陷入细节之中。

自顶向下的方法很适合如今的抽象和面向对象设计方法。学生从顶层计算机系统开始，逐步细化，得到更低的层次。例如，可以从高级语言开始，说明如何将高级语言编译为机器指令，然后介绍如何在框图一级实现这些指令，接下来介绍功能电路，最后以门设计电路收尾。

不同的教授会选择不同的教学方法，我却认为教育的结果更多地取决于教授的能力，而不是他所选择的教学方法。我个人采用自顶向下和自底向上相结合的方法进行教学。


## 存储程序计算机

定义术语“计算机”时必须指明计算机的类型。

数学家约翰·冯·诺伊曼时最早界定计算机结构的人之一，为了纪念他而命名的 `冯·诺伊曼存储程序数字计算机` 是从个人计算机到手机等多种系统的核心。

其他类型的计算机还有模拟计算机、神经计算机、量子计算机以及生化计算机。它们处理信息的方式与存储程序计算机（数字计算机）完全不同。



如果一台计算机能够模拟图灵机（阿兰·图灵发明的一种抽象计算机模型），那它就是图灵完备的。今天所有的计算机都是图灵完备的，这意味着所有计算机都能解决同样一些问题，换句话说，能由计算机 A 解决的问题也一定能由计算机 B 解决。

这样看来，未来的计算机也没有办法解决那些现有计算机解决不了的问题。

当然，其中一台可能比另外一台更快或更便宜一些，但是从解决的问题角度它们是相同的。



数字计算机可被分为两部分：中央处理单元和存储器系统。

* CPU 读程序并完成程序指定的操作。
* 存储器系统保存两类信息：程序（指令），程序（指令）处理或产生的数据。

使用术语“组成（organization）”代表计算机的实际硬件实现，包括它的 CPU、存储器、总线以及输入/输出机制。

使用术语“微体系结构（micro-architecture）”代表 CPU 的实现。



计算机体系结构含有“结构（structure）”的意思，描述了一些与计算机组成方式有关的内容，通常被认为是程序员视角中的计算机。程序员所看到的是计算机的抽象视图，对它们来说，计算机的实际硬件和实现都被隐藏起来了，程序员可以在完全不清楚加法操作如何进行的情况下指示计算机将 A 与 B 相加。这个抽象视图现在通常被称作 `指令集体系结构（instruction set architecture, ISA）`

将体系结构和实现完全分离是错误的，因为二者是相互影响的。一种给定的体系结构可能最适合采用 X 技术实现，另一种体系结构则可能最适合采用 Y 技术实现，即使每种体系结构都能采用 X 技术和 Y 技术实现。

指令集体系结构包括：

* 数据类型（每个字的位数以及各个位的含义）
* 用来保存临时结果的寄存器
* 指令的类型和格式
* 寻址方式（表示数据在存储器中存放位置的方法）



我们需要定义术语“时钟”。绝大多数数字电子电路中都带有一个时钟，用以生成连续的固定间隔的电脉冲流。之所以被称作时钟，是因为可以用这些电脉冲来计时或确定计算机内所有事件的顺序。例如，某处理器可能会在每个时钟脉冲到来时执行一条新的指令。



算法：算法是一个用来完成某个功能的长度有限的明确定义的指令序列（即计算一个函数或完成一项给定的任务）。一些计算机科学的基础教材中以菜谱为例，认为菜谱就是制作一道菜的算法。

程序：程序是实现一个算法的一组计算机指令。也即，程序是用特定方式描述的一个算法的实例，其目的是在一台特定的计算机上求解问题。程序中包含的信息可能比算法描述的更多，因为程序必须构建一个合适的环境。

伪代码（伪码）：伪代码介于算法和程序之间。伪代码在本质上就是一个用特定的类程序设计语言描述的算法。伪代码的目的是使程序员可以用它描述一个算法，而读者不必摄入了解特定的程序设计语言。



常量：程序执行过程中不会被修改的值。

变量：程序执行过程中会发生改变的值。

符号名：未了便于记忆和理解而用来引用变量和常量的名字。

地址：计算机将信息保存在存储器中，每个位置都有一个唯一的地址。

值和地址：表达式 $c=2\pi r$ 中的 $r$ 表示什么，值还是位置？人们将 $r$ 视作代表圆半径的符号名，比如是 5。但是，计算机却将 $r$ 看作地址 1234 的符号名，必须进行存储器读访问才能得到实际值。那么表达式 $r=r+1$ 是表示修改半径的值（$r=5+1=6$）还是修改地址的值（$r=1234+1=1235$）呢？区分存储单元的地址和它的值非常重要，特别是在理解指针这个概念时。

指针：指针是一个变量，它的值表示存储地址。

# 存储器

存储系统的组成：

* 处理器将一个放在 `地址总线` 上的地址以及一个用于选择 `读操作` 或 `写操作` （它们有时也被称作读或写周期）的控制信号发送给存储器。

* 在读周期中，存储器将数据放在 `数据总线` 上供 CPU 读取；在写周期中，放在数据总线上的数据被写入存储器。
* 信息进入或离开存储器的位置（或计算机系统的其他功能部分）叫做 `端口`

![image-20220620165220669](D:\Codes\study-notes\计算机基础.assets\image-20220620165220669.png)



一台真正的计算机会使用存储系统层次（每个层次都有可能采用不同的技术实现）。这些层次包括保存频繁被访问数据的速度非常快的 Cache、主存，以及速度非常慢的辅存，在这一层次中大量数据会一直保存在磁盘、光盘或 DVD 中，直到使用时才会被调入主存。



寄存器传输语言（Register Transfer Language, RTL）：

* 方括号 `[]` 表示存储单元的内容；
* 左箭头符号 `⬅`  表示数据传送操作；等价于传统赋值符号 `=`

举例如下：

`[20] = 5`：地址为 20 的存储单元的值等于数字 5

`[20] ⬅ [5]`：地址为 5 的存储单元的值复制到地址为 20 的存储单元



存储程序计算机的基本操作：

```
START
    程序计数器指向存储器中的第一条指令
    REPEAT
        从程序计数器所指向的存储单元中读出指令
        修改程序计数器，使之指向下一条指令
        将从存储器中取出的指令解码
        执行指令
    FOREVER
END
```

使用 C 语言描述

```c
InstructorPointer = 0;
do
{
    instruction = memory[InstructorPointer];  /* 读取指令      */
    decode(instruction);                      /* 解码指令      */
    fetch(operands);                          /* 获取需要的数据 */
    execute;                                  /* 执行指令      */
    store(results);                           /* 存储结果      */
} while (instruction != stop);
```

在一台计算机上执行一条指令需要至少两次访存（这句话适用于每条指令都会访存以存取数据的计算机）。第一次访存是读取指令，第二次访存要么从存储器中读出指令需要的数据，要么将它之前的指令产生的或修改过的数据写回存储器。有时候也称存储程序计算机时按照 `读取/执行（fetch/execution）` 周期的两个阶段模式工作的。

因为每条指令必须两次访问存储器，人们用 `“冯·诺伊曼瓶颈”` 一词表明 CPU 与存储器之间的通路是存储程序计算机的制约因素之一。人们设计了不同体系结构的机器来解决这一问题。



存储程序计算机上执行的指令的格式：

* 三地址指令

  `Operation Address1, Address2, Address3` ，例如 $P=Q+R$ 。

  RTL 符号表示为 `[Address1] ⬅ [Address2] Operation [Address3]`

  该指令是假想的，它没有在任何一台现代计算机上实现。

* 两地址指令

  `Operation Address1, Address2` ，例如 $R=Q+R$ 。

  RTL 符号表示为 `[Address1] ⬅ [Address1] Operation [Address2]`

  在实际的计算机中，一般都不会允许同一条指令中使用两个存储地址。绝大多数计算机都规定一个地址是 `存储器` 地址，另一个地址是 `寄存器`。

  寄存器是计算机内的存储单元，其名如 $r0,r1,r2,…,r31$ ，用来保存计算过程中生成的临时数据。

* 单地址指令

  `Operation Addres` 

  由于指令中只提供了一个操作数地址而指令却需要至少两个地址，处理器不得不使用一个不需要显式地址的第二个操作数。也就是说，第二个操作数来自 CPU 内一个叫做 `累加器（accumulator）` 的寄存器。



`寻址方式` 是计算机指令集的一个重要特征，它是确定操作数位置的方法。可以 `直接` 或 `间接` 给出操作数的地址。

* 直接：操作数的地址为 1234
* 间接：寄存器 5 的内容是我们需要的操作数的地址



我们可以按照计算机指令处理数据的方式对计算机分类：

* 存储器-存储器型：从存储器中读出源数据，完成指令操作后，将结果保存在存储器中。
* 寄存器-存储器型：能够同时处理两个数据，其中一个位于存储器中，另一个位于寄存器中，结果要么被写回存储器，要么被写回寄存器
* 寄存器-寄存器型：只能对寄存器中的内容进行操作



存储层次：

* 寄存器：寄存器存放处理器的工作数据，最快访问速度 1ns

* Cache：Cache 缓存常用数据的快速处理器，最快访问速度 10ns

  Cache 系统与计算机的地址总线和数据总线相连，监听者 CPU 与存储器之间的事务

* DRAM：动态随机访问存储器（Dynamic Random Access Memory, DRAM），主存，存放工作数据块，最快访问速度 40ns

* 硬盘：保存程序和数据，最快访问速度 20ms



总线将计算机的两个或多个功能单元连接在一起并允许它们互相交换数据。

总线互联的问题在于只有唯一一个设备能够与其他设备通信，因为只有一条信息通路。如果两个设备同时请求使用总线，它们不得不去竞争总线的控制权。我们用术语 `仲裁` 来描述这种两个或多个设备竞争同一资源（特别是总线）的过程。一些系统使用一个名为 `仲裁器` 的专用部件来决定允许哪个设备继续工作，而其他竞争者只能等待轮到自己。

总线术语：

* 宽度：一般用并行数据通路的数量来定义总线的宽度。一条 64 位宽的总线一词能够传送 64 位（8 个字节）的信息。

  这个术语也会用来表示构成总线的连接线的总数。例如，一条总线可能含有 50 条信息通路，其中 32 条用来传输数据（其余的可能是控制通路甚至是电源线）。

* 带宽：`总线带宽` 是衡量信息在总线上的传输速率的一项指标。带宽的单位要么是 B/s，要么是 b/s。

  在保持数据传输率不变的情况下增加总线的宽度，可以提高带宽。

* 延迟：延迟是从发出数据传输请求到实际数据传输的时间间隔。总线延迟通常包括传输开始之前进行总线仲裁的时间。

现代计算机中有多条总线，包括片内总线、功能单元间（如 CPU 和存储器间）总线以及总线间的总线。



标准：标准是一种约定好的设计系统、定义系统或对其他任何方面进行分类的方式。例如，为了允许人们将电子设备从一个地方移到另一个地方，电源插座和插头必须符合约定的标准。

协议：协议与标准类似，但它覆盖的范围较窄。协议决定了双方通信时各事件的发生顺序。例如，当计算机将数据发送给存储器时，写协议定义了信号序列（地址、写命令、要保存的数据）以及信号的最长和最短持续时间。





# 计算机算数

“我常说：当你能衡量你正在谈论的东西并能用数字加以表达时，你才真的对它有了几分了解；而当你还不能测量，也不能用数字表达时，你的了解就是肤浅的和不能令人满意的。尽管了解也许是认知的开始，但在思想上则很难说你已经进入了科学的阶段。” ——Lord Kelvin

## 整数位置计数法

位置计数法，一个 n 位的整数 N 可以按照下面的形式书写：
$$
N=a_{n-1},a_{n-2},...,a_{i},...,a_{1},a_{0}
$$
这里的 $a_{i}（i=0,1,...,n-1）$ 是与 $b$ 幂相乘的系数（此处 $b$ 为基数）。例如，当基数为 10 时，我们可以将 $N=277$ 写作 $a_{2}a_{1}a_{0}$ ，这里 $a_{2}=2,a_{1}=7,a_{0}=8$。

因此，一个基底为 $b$ 的位置计数法表示的数的值被定义为：
$$
\begin{aligned}\label{2}
N &= a_{n-1}b^{n-1}+a_{1}b^{1}+a_{0}b^{0}+a_{-1}b^{-1}+a_{-2}b^{-2}+...+a_{-m}b^{-m} \\
  \\
  &= \sum_{i=-m}^{i=n-1}a_{i}b^{i}
\end{aligned}
$$
采用位置计数法，一个数的数值的关于它各位值的总和，而每一位的值则是该位的数值乘以它在数中位置所对应的权。



## 二进制小数误差和准确度问题

计算机算术的重要术语：

* 表示范围（range）：一个数所能表示的最大值和最小值的差。例如，一个 $n$ 位二进制自然数的表示范围是 $0\sim2^n-1$ 之间的值。表示范围在科学计算应用中尤其重要，特别是当需要表示银河系的大小或银行家的红利那样的天文数字时，或表示电子的质量那样微观的很小的值时。
* 精度（precision）：数的精度是数据表示得有多好的衡量标准之一。例如，$\pi$ 就不能用二进制或十进制实数精确地表示——无论用多少位都不行。如果用 5 位十进制数表示 $\pi$，则其精度为 $10^{5}$ 分之一；如果是 20 位，则其精度为 $10^{20}$ 分之一。
* 准确度（accuracy）：数的表示值与其真实值之间的差值，衡量了数据表示的准确度。例如，我们测量某种液体的温度为 51.32℃，而它的实际维度为 51.34℃，则准确度误差为 0.02°。
* 误差（error）：误差是准确度的一个衡量标准，即误差 = 真实值 - 测量值。对于计算机设计者、程序员和用户而言，重要的是误差如何产生、如何控制误差以及如何将误差的影响降到最小。

二进制小数带来了二进制算术运算中的误差和准确度问题。

如果有足够的位数用于数据表示（即一个足够大的表示范围），那么任何一个十进制整数都可以被表示为二进制形式。

二进制小数的位置计数法表示为 $0.1_{2}=0.5_{10}$ ， $0.01_{2}=0.75_{10}$ ， $0.001_{2}=0.125_{10}$ ……。 二进制小数的一个特点是，即使用了很多位，也不能将所有的十进制小数准确地表示为二进制形式。例如 $0.1_{10}=0.0001100011001100110011..._{2}$ ，无论用多少位都不能准确地将 $0.1_{10}$ 表示为二进制形式。在 32 位的机器上，数据表示的精度为 $2^{32}$ 分之一。



## 有符号整数

计算机设计者使用三种方法表示负数：

* 符号及值表示：一个 $n$ 位的字可以表示 $0\sim2^{n-1}$ 个可能的值。表示负数的一种方法是用它的最高位表示符号。通常 0 表示正数，1 表示负数。 $n$ 位有符号可以表示 $-(2^{n-1}-1)\sim+(2^{n-1}-1)$ 之间的整数。

  符号及值表示法并没有用于整数算术运算中，因为它的加、减法运算需要分别用加法器和减法器实现。

* 二进制补码表示：微处理器用二进制补码系统表示有符号整数，因为它可以将减法运算转换为对减数补码的加法运算。

  在二进制算术中，一个 $n$ 位二进制数 $N$ 的二进制补码为  $2^n-N$ 。也可以说是将其各位取反并加 1。

  求补运算：

  $2^n-N=2^n-1-N+1=\underbrace{111\cdots1}_{n个}-N+1$ ，即各部位取反再加 1。

  二进制补码算术是一种非常巧妙的计算方式。请考虑 $n$ 位二进制算术运算 $Z=X-Y$ ，我们用 $X$ 加上 $Y$ 的补数来完成这一运算。$Y$ 的补码为 $2^n-Y$ ，则有 $Z=X+(Y_补-2^n)=(X+Y_补)-2^n$ ，这样就将减法运算变为了加法运算。

  

  注：《计算机组成原理》一书中对于补码的描述不完全正确。

  正数的补码是其本身，负数的补码是 $2^n-N$ 。

  

  补码的最高位为符号位：如果符号位为 0，则该数为正；如果符号位为 1，则该数为负。

  补码运算溢出：系统通过加法器的进位输入和输出的最高位来判断是否发生溢出，即 $V=C_{in} \neq C_{out}$ 。

* 移码表示：进行移位运算时，一个数的所有位都会向左或向右移动一位或多位。

  二进制数左移一位：相当于这个数乘以 2

  二进制数右移一位：相当于这个数除以 2，丢弃最低位

  负数右移需要考虑符号位，左侧补符号位

![image-20220801164535192](D:\Codes\study-notes\计算机基础.assets\image-20220801164535192.png)



## 无符号整数乘法

![image-20220801161330306](D:\Codes\study-notes\计算机基础.assets\image-20220801161330306.png)

## 有符号整数乘法

![image-20220801165258031](D:\Codes\study-notes\计算机基础.assets\image-20220801165258031.png)



## 恢复余数除法

除法时通过被除数不断地减去除数，直到结果为零或小于除数来实现的。减去除数的次数称作“商（quotient）”，最后一次减法的差称作“余数（remainder）”。
$$
被除数/除数=商+余数
$$
和十进制除法类似，但二进制除法无需多次减去除数，仅需一次。

且必须将除数的最高位和被除数的最高位对齐。

![image-20220801172247980](D:\Codes\study-notes\计算机基础.assets\image-20220801172247980.png)

## 不恢复余数除法

不恢复余数除法可以减少除法的延迟，其基本逻辑相同，但取消了恢复余数操作。

![image-20220801173602219](D:\Codes\study-notes\计算机基础.assets\image-20220801173602219.png)

## 浮点数

浮点运算，即实数之间的运算。实数时所有有理数和无理数的集合。

浮点运算能够让人们处理科学应用（与金融或商业应用相对）中很大的和很小的数（例如，从电子的质量到星体的质量）。

这些数被表示为浮点数时因为小数点在数种的位置并不是固定的。一个浮点数值被分为两个部分存储：数值，以及小数点在数值种的位置。

浮点数表示也被称作“科学计数法”，十进制运算中，科学计数法表示的数字被写成 $尾数\times10^{指数}$ 的形式，二进制浮点数则被表示为 $尾数\times2^{指数}$ 的形式。

多年以来，计算机系统使用了很多不同的方法表示浮点数的尾数和指数。20 世纪 70 年代，一种标准的浮点数表示方法快速地取代了大多数系统自有的格式。IEEE 754 浮点数标准提供了 3 种浮点数表示：

* 32 位单精度浮点数
* 64 位双精度浮点数
* 128 位四精度浮点数

IEEE 754 浮点数的尾数总是规格化的，其范围为 $1.000…0\times2^e$ 到 $1.111…1\times2^e$ 这里的 e 为指数。规格化浮点数的最高位总是 1。

IEEE 754 浮点数的尾数被表示为符号和数值的形式，即用一个符号位表示它是正数还是负数。

它的指数则用 `偏置` 方式表示，即给真正的指数加上一个常数。

一个 32 位 IEEE 754 单精度浮点数可以表示为下面的二进制位串：

S EEEEEEEE 1.MMMMMMMMMMMMMMMMMMMMMMM

S 表示符号位，指明这个数是正数还是负数；E 表示 8 位偏置指数，指出了小数点的位置；M 表示 23 位小数尾数。细数这个数，会发现它有 33 位而不是 32 位，是因为在计算机存储器中保存时，尾数前的 1 被省掉了。

一个非 0 的 IEEE 754 浮点数可以被定义为：
$$
X=-1^S \times 2^{E-B} \times 1 \cdot F
$$

S = 符号位；E = 偏置量为 B 的指数；F = 尾数的小数部分

![image-20220802093328086](D:\Codes\study-notes\计算机基础.assets\image-20220802093328086.png)



非数（Not a Number, NaN）是 IEEE 754 标准的一个重要概念，它代表 IEEE 754 标准格式所不能表示的数。

十进制和二进制转换样例：

![image-20220802094229050](D:\Codes\study-notes\计算机基础.assets\image-20220802094229050.png)



## 浮点数运算

浮点数加减法运算，和十进制加减法运算类似，将小数点对齐后相加，再转换为符合 IEEE 754 标准的浮点数。

浮点数乘法运算，将指数相加，尾数相乘，再转换为标准的浮点数。

当浮点数运算导致尾数长度溢出时，有两种处理方式：截断（truncation）和舍入（rounding）。二者都会导致运算的误差。

IEEE 标准要求加、减、乘和除的运算结果能够精确计算，并用向偶数舍入的方法将结果舍入为最近的浮点数。

## 浮点数运算误差

在计算机中，整数的运算不会产生误差，是精确的。但浮点数运算不是精确的，甚至对不同的计算芯片而言，同样的输入会产生不同的输出。

例如表达式 $z=x^2-y^2=(x+y)(x-y)$。无论使用哪个表达式，整数运算都会得到同样的结果，但浮点运算可能会得到不同的值，这取决于浮点数计算误差的大小。

执行浮点计算链时，舍入造成生成误差（generated error）或通过计算链传播的传播误差（propagated error）都会被引入。

假设 $X^{’}$是计算机使用的 $X$ 值，它被定义为 $X+R_x$ ，这里的 $X$ 为真正的值，而  $R_x$ 为舍入带来的误差。$X$ 的相对误差被定义为  $R_x/X$ 。

当程序员在操作  $X+Y$ 时，计算机要完成的是  $X+Y+R_x+R_y$ 。这个表达式表明，加法运算中的舍入误差将会被累积。

乘法操作也是类似的。



# 计算机指令集结构

计算机的指令集体系结构（ISA）从汇编语言程序员的角度描述了计算机，并强调了计算机的功能，而不是它的内部组成或实现。 ISA 说明了计算机能做什么，而计算机组成则说明了它是如何做的。



## 取指-执行模式

ARM 这一类处理器采用了存储程序体系结构，它将程序和数据放在同一个存储空间内，采用 `取指-执行` 模式执行，即按照顺序从内存读取指令、译码、执行。这样一台计算机带有寄存器、算术逻辑单元（ALU）、存储器以及用来连接各个功能部件的总线。



寄存器是位于 CPU 内部的存储单元，类似于内存中的存储单元。寄存器使用名字而不是地址来访问，比如 r0，r1，…，r15（ARM 的命名），这样计算机指令的操作码就可以使用很少的几位来引用寄存器。

CPU 中的寄存器有几个功能：

* 一些寄存器是高速暂存（Scratchpad）寄存器，用于保存数据或者数据单元中的地址（即指针）
* 另外一些则是特殊功能寄存器，比如对一个循环的次数进行计数的循环计数器，有的则用来记录处理器的状态

CPU 中最重要的寄存器是程序计数器（PC），它记录了要执行的下一条指令的地址，也就是说，程序计数器保持对程序执行的跟踪。有时 PC 也叫指令指针，这更能反映出它的功能。



假定 ARM 提供了以下 3 种指令格式：

* **LDR 寄存器，存储单元**：LOAD，将存储单元的数据加载到寄存器
* **STR 寄存器，存储单元**：STORE，将寄存器中的数据保存到存储单元
* **Operation 寄存器，寄存器 1，寄存器 2**：将寄存器 1 和寄存器 2 中的数据做某种操作（例如：ADD、SUB 等）后保存到寄存器



假定存在以下寄存器：

* MAR 地址寄存器，保存了读或者写操作正在访问的存储单元的地址
* MBR 数据寄存器，保存了刚从存储器中读出的数据，或将写入存储器的数据
* PC 程序计数器，保存了要执行的下一条指令的地址
* IR 指令寄存器，存放最近从存储器中读出的指令，也就是当前正在执行的指令，包括操作码和操作数
* r0-r7 寄存器文件，用于存放临时数据（例如计算的中间结果）

使用 RTL 符号表明一个取指-执行周期：

```
FETCH:
    [MAR] <- [PC]        ；把 PC 的值复制到地址寄存器
    [PC]  <- [PC] + 4    ；PC 递增，指向下一条指令
    [MBR] <- [[MAR]]     ；读出地址为 MAR 的指令
    [IR]  <- [MBR]       ；把指令从 MBR 复制到 IR
LDR:
    [MAR] <- [IR(addr)]  ；把 IR 中的操作数地址复制到 MAR
    [MBR] <- [[MAR]]     ；读出地址为 MAR 的操作数
    [r1]  <- [MBR]       ；把操作数移到寄存器 r1 中
```



图示如下：

![image-20220816142458170](D:\Codes\study-notes\计算机基础.assets\image-20220816142458170.png)



## ISA 的组成

ISA 由三个部分组成：

* 寄存器
* 寻址方式
* 指令格式

它们共同定义了汇编语言程序员看待处理器的视角。

实际上，有两个汇编语言程序员：`人` 和 `编译器` 。编写汇编语言程序的人类程序员要么是正在课堂上学习计算机体系结构的学生，要么是正在编写计算机代码或者正在进行汇编语言级系统调试的专家。绝大多数低级或机器代码由编译器自动生成，编译器把高级语言翻译为低级或机器代码。

人们可以充分利用机器指令集编写出相当紧凑或高效的代码，但用这种方法编写大型程序非常困难。而且，一个人使用精妙的设计技巧编出的汇编语言代码对于另一个人来说通常是很难理解并且不可读的。人们编写的高级语言代码要比低级语言代码更加有效、更加可靠。

编译器还无法挖掘出处理器的所有特性，一个对人们来说很好的体系结构对编译器而言并不一定优秀。



## 寄存器

从概念上来看，寄存器是计算机中最没有用的一部分，它甚至是没有必要的，也不参与任何计算。

然而，寄存器对于提高计算机性能和实际指令集设计是很有必要的。一般来说，CPU 寄存器内可直接访问的数据越多，处理器的速度就越快。



载入与存储（load-store）计算机：

由于 CPU 上只带有少量的片内寄存器，因此有必要通过将数据载入寄存器，和将寄存器中的数据存入存储器的指令，在内存和寄存器之间传递数据。

如果对存储器的操作只能是将数据传送到寄存器，或者从寄存器中取出数据，这类计算机被做载入与存储（load-store）计算机，被归为 RISC 一类。



8086 所使用的 IA32 体系结构使用了一组特定的 16 位寄存器，叫做 AX、BX、CX 和 DX，每个寄存器可被分解为一对寄存器（例如 AH 和 AL），用作字节寄存器。它还有 4 个变址（指针）寄存器和 4 个段寄存器（用于打破因 16 位指针寄存器导致的 64K 页大小限制）。需要强调的是，8086 的寄存器都是高度专用的，程序员必须记住每个寄存器能做什么，以及哪条指令使用哪个寄存器。例如：寄存器 C 是专用的计数寄存器。

提供特殊功能寄存器意味着无需在指令中分配一些位去指明它的用途。例如，如果寄存器被定义位计数器，那么增加计数值的指令就可以不需要寄存器地址，因为计数器已经与指令绑定在一起。使用专用寄存器会使代码更加紧凑，这在微处理器发展的早期是一个非常重要的特性，因为早期存储器的价格是现在的数百万倍。

ARM 有 16 个通用寄存器 r0-r15。寄存器 r0-r13 可互换使用，行为相似。寄存器 r14 和 r15 还有额外的功能（r14 位链接寄存器，保存子程序返回地址；r15 为程序计数器）。尽管人们希望能自由地使用寄存器 r13，但良好的编程实践却要求保留 r13 以使用栈指针。



## 寻址方式

指令对数据进行操作，并且必须将数据移动到其被处理的地方。指定数据的方式统称为“寻址方式”。

尽管有许多变种，但原则上一共有 3 种基本的寻址方式：

* **立即数寻址（literal addressing）**：立即数寻址意味着操作数为常数，此时操作数立即可用，无需从寄存器或存储器中读取。

  `ADD r0, r1, #Q` ，RTL 表达式 `[r0] <- [r1] + Q` ，把整数 Q 与寄存器 r1 的内容相加

  `MOV r0, #Q` ，RTL 表达式 `[r0] <- Q` ，把整数 Q 加载到寄存器 r1 中

* **直接寻址（direct addressing）**：也称为绝对寻址。这种寻址方式是把存储器操作数地址用作指令的一部分。load-store 型计算机，比如 ARM，没有实现直接寻址，所有存储器操作数要么被指定为立即数，要么通过寄存器指针间接指定。

  `LDR r0, Mem` ，RTL 表达式 `[r0] <- [Mem]` ，将存储单元 Mem 中的内容加载到寄存器 r0 中。ARM 不支持这种寻址方式，但所有的 CISC 处理器都支持

* **间接寻址（indirect addressing）**：更严格地说，叫做寄存器间接寻址。指令中给出了包含存储器操作数地址的寄存器地址。获得一个操作数需要 3 次访问：读指令，读含有操作数地址的寄存器，从存储器中读出实际的操作数。

  `LDR r0, [r1]` ，RTL 表达式 `[r0] <- [[r1]]` ，把 r1 所指的存储单元的值加载到寄存器 r0 中

![image-20220816161251446](D:\Codes\study-notes\计算机基础.assets\image-20220816161251446.png)



由上述的寻址模式，微处理器一般提供 3 种指令模式：

* 存储器-寄存器型：源数据在存储器中，目的数据在寄存器中；
* 寄存器-存储器型：源数据在寄存器中，目的数据在存储器中；
* 寄存器-寄存器型：两个数据都在寄存器中；

事实上，确实存在存储器-存储器型操作，但一般



## 指令格式

指令格式一般包括：操作码、操作数

按照操作数的数量，可以将指令分为：

* 3 操作数指令：例如 ADD P, Q, R ：Q 和 R 相加，结果放在 P 中
* 2 操作数指令：例如 ADD P, Q ：P 和 Q 相加，结果放在 P 中
* 1 操作数指令：例如 ADD P ：P 与累加器相加，结果放在累加器中
* 0 操作数指令：例如 ADD ：从栈中弹出两个数相加，结果放在栈顶

按照指令的性质，可以将指令分为：

* 数据移动指令：将数据从一个地方复制到另一个地方
* 数据处理指令：进行数据运算
* 流控制指令：修改指令执行顺序



指令受到字长的限制：操作码位数 + 操作数位数 = 计算机字长。

因此，微处理器不处理 3 操作数的地址指令（操作数位数超长）。

按照指令中包含的操作数，可以将计算机分为：

* 双地址计算机：

  CISC 计算机（像是 Pentium 或 68K）采用双地址指令格式。双操作数指令的代价时一个源操作数的内容会因为覆写而遭到破坏。绝大多数计算机指令不能直接访问两个存储单元，典型情况下，操作数要么是两个寄存器，要么是一个寄存器和一个存储单元。

* 单地址计算机：

  但地址计算机在指令中仅指定了一个操作数，第二个操作数是一个叫累加器的固定寄存器，无需指定。

  目前但地址计算机仍被广泛地应用于超低功耗、低性能的系统中，比如玩具。

* 零地址计算机：

  零地址计算机使用根本没有地址的命令，只对栈顶的数据进行处理，因此通常也被称做 `栈计算机` 。一个纯粹的零地址计算机时不实用的，需要通过 load 和 store 指令从存储器中读出数据或把数据保存到存储器中。

  1980 年，查尔斯·摩尔（Charles Moore）发明了基于栈的编程语言 Forth，主要用于控制应用（例如望远镜、机器人等等）。高级语言 Java 被编译程一种低级的基于栈的语言，叫做字节码（bytecode），并在真实计算机上解释执行。有些 ARM 处理器集成了 Jazelle 直接字节码执行（Direct Bytecode eXecution，DBX），能够直接执行字节码。由硬件直接执行字节码（而不是解释执行）提高了 ARM 运行 Java 应用时的性能。

* 一个半地址计算机：

  Intel IA32 系列与 Freescale 系列通常叫作一个半地址计算机，这是因为它们的指令指定了两个操作数，一个操作数时存储器地址，另外一个操作数则是寄存器地址。寄存器地址被讽刺地称为半个地址，因为与 GB 量级的存储空间相比，寄存器的数量很少。



## ARM 指令集体系结构

### ARM 寄存器

![image-20220817101209387](D:\Codes\study-notes\计算机基础.assets\image-20220817101209387.png)

* r0-r12 通用寄存器
* r13 栈指针（sp）
* r14 链接寄存器（lr）
* r15 程序计数器（pc）
* CPSR 当前处理器状态寄存器，包括 Z（零）、N（负）、C（进位）、V（溢出）等标志位。



### ARM 指令集

分类包括：数据移动、算术运算、逻辑运算、移位和程序控制。



与绝大多数 CISC 体系结构不同，ARM 不会在算术和逻辑运算后自动更新状态标志。ARM 提供了一种按需更新模式，仅在当前指令助记符带有后缀 S 时才会自动更新条件码。



ARM 的指令格式如下：

```
Label Op-code operand1, operand2, operand3	;comment
```

* Label 是用户定义的标号，由其他指令（如条件分支指令）使用，用来引用标号所在的那一行；
* 分号后面的文本为注释字段，会被汇编器忽略。注释提高了程序的可读性。



汇编语言：

汇编程序由两部分语句组成：计算机 `可执行指令` 和汇编器运行环境有关信息的 `汇编伪指令` 。

伪指令是程序员可用的指令，但不是处理器 ISA 的一部分。伪指令是一种速记形式，程序员可以用它简单地表示一个动作，并使汇编器可以生成合适的代码。例如：汇编伪指令 ENTRY 告诉汇编器在哪里找到要执行的第一条指令；END 告诉汇编器已经到达程序末尾。

EQU 和 DCD 是两个重要的汇编伪指令：

* EQU 把一个名字和一个值绑在一起，用名字来替代数值的原因是为了则更加程序的可读性
* DCD 在程序运行前将数据提前载入存储空间



### 算术指令

* 加法：ADD、ADC
* 减法：SUB、SBC、RSB
* 取负：NEG、MVN
* 比较：CMP
* 乘法：MUL、UMULL、UMLAL、SMULL、SMLAL
* 累加：MLA
* 位操作：AND、OR、NOT、EOR、BIC
* 移位：LSL、LSR、ASL、ASR、ROL、ROR



加法操作：

* ADD：两个字相加的一般化操作，不更新状态标志
* ADDS：两个字相加的一般化操作，更新状态标志
* ADC：带进位的加法指令（将两个操作数和状态寄存器中的进位位加到一起），实现链式计算

减法操作：

* SUB：两个字相减的一般化操作，不更新状态标志
* SUBS：两个字相减的一般化操作，更新状态标志
* SBC：带错位的减法指令（将两个操作数和状态寄存器中的进位位加到一起），实现链式计算
* RSB：逆减法，和 SUB 减法的减数和被减数相反，`SUB r0, r1, r2;  r0 <- r1 - r2`；`RSB r0, r1, r2;  r0 <- r2 - r1` 

取负操作：

* NEG：取负，零减去一个数字，可以使用减法指令或逆减法指令来实现
* MVN：取反传送，将一个寄存器中的值实现逻辑取反（按位取反），保存到另一个寄存器中

比较操作：

* 隐式比较，例如 ADDS 或 SUBS 操作，会更新状态位，可以直接用于判断
* CMP：显示比较，计算两个操作数相减是否为零，并更新状态位 CPSR

乘法操作：

* MUL：32 位乘法指令，计算保存两个 32 位有符号数的积，然后保存 64 位积的低 32 位
* MLA：32 位乘累加指令，计算结果保存 64 位积的低 32 位，采用四操作数形式：`MLA Rd, Rm, Rs, Rn` 的 RTL 定义为 `[RD] <- [Rm] × [Rs] + [Rn]` 
* UMULL：无符号长整形乘法，乘积为 64 位，存放在两个寄存器中
* UMLAL：无符号长整形乘累加
* SMULL：有符号长整形乘法
* SMLAL：有符号长整形乘累加

除法操作：

* ARM 没有实现除法操作，程序员必须自己编写除法子程序



### 位指令

位（bitwise）操作也叫逻辑操作，因为这些操作被用用到寄存器的每一位。布尔变量一共有 16 个可能的逻辑操作，但微处理器一般只支持 AND、OR、NOT 和 EOR 操作。

逻辑操作：

* AND：逻辑与，两个位均为真（1）时结果为真，例如：$$ 11001010·00001111=00001010 $$ 
* OR：逻辑或，两个位任意为真时，结果为真，例如：$$ 11001010+00001111=11001111 $$ 
* NOT：逻辑非，按位取反，例如：$$ \overline{11001010}=00110101 $$ ARM 不支持 NOT 操作，但可以通过 EOR 和 #1 来实现，因为 $x\oplus1$ 就是 $\overline{1}$ ；也可以通过 MVN 指令来实现。
* EOR：逻辑异或，两个位不同时，结果为真，例如：$$ 11001010\oplus00001111=11000101 $$
* BIC：位清除，将第一个操作数和第二个操作数的反码进行逻辑与操作，即第二个操作数的某位为 1，则将第一个操作数对应的位清零，例如：$$ 10101010·\overline{00001111}=10100000 $$ 



### 移位指令

移位操作：

* LSL：逻辑左移，将最左侧的位移出到状态寄存器的进位位，在最右侧移入 0
* LSR：逻辑右移，将最右侧的位移出到状态寄存器的进位位，在最左侧移入 0
* ASL：算术左移，将最左侧的位移出到状态寄存器的进位位，在最右侧移入 0，等价于逻辑左移。ARM 没有实现算术左移
* ASR：算术右移，将最右侧的位移出到状态寄存器的进位位，在最左侧复制符号位
* ROL：循环左移，将最左侧的位移出到状态寄存器的进位位，同时将该位移入最右侧。ARM 没有实现循环左移，但可以通过循环右移实现它
* ROR：循环右移，将最右侧的位移出到状态寄存器的进位位，同时将该位移入最左侧
* RRX：带进位的循环右移，仅允许移动一位



ARM 没有独立的移位，而是作为其他指令的一部分来实现的。ARM 处理器允许对寄存器-寄存器型指令的第二个操作数进行移位，不会增加完成指令的时钟周期。例如：ADD r0, r1, r2, LSL #4，将第二个操作数逻辑左移 4 位后再做相加，在一条指令中完成。



ARM 移位指令编码方式：

![image-20220817115350674](D:\Codes\study-notes\计算机基础.assets\image-20220817115350674.png)



### 流控制指令

* 无条件分支指令：B target
* 条件分支指令：BXX target

![条件分支指令](D:\Codes\study-notes\计算机基础.assets\image-20220817120057789.png)



在高级语言中，无条件分支叫做 `goto`，而且它的使用被认为是一种比较糟糕的编程风格。然而在汇编语言（低级）程序设计中，它是很难避免的。人们总是在执行了程序中一段特别的路径之后，再用它返回到某个公共位置。无条件分支实际上就是“返回”指令。



### 测试与比较指令

* TEQ：相等测试指令，确定两个操作数是否相等。如果相等则将状态位 Z 置为 1，否则清零。TEQ 指令在测试时仅修改状态位 Z，而 CMP 指令除了修改 Z 外，也会修改溢出位 V
* TST：测试指令，通过逻辑与操作来比较两个操作数，然后根据测试结果更新状态位。可以用 TST 来测试一个字中的每一位。
* CMP：比较指令，上文曾描述过
* CMN：取负并比较指令，在比较之前先将第二个操作数取负，然后设置状态位 CPSR，注意 `[r1] - [-r2]` 的值等同于 `[r1] + [r2]` 



### 条件执行指令

ARM 的每条指令都是条件执行的，因此可以将指令与逻辑条件（参考流控制指令中的 16 个助记符）关联在一起。如果条件为真，则指令正常执行，否则指令会被旁路（无效或转换为空操作）。

条件执行使用助记符：

例如 EQ 判断 Z 位是否为 1，因此 `ADDEQ r0, r1, r2` => `if(Z=1) then [r1] <- [r2] + [r3]` 



### 加载和存储指令

ARM 实现了加载和存储指令：

* LDR：加载，把存储器的值，加载到寄存器
* STR：存储，把寄存器的值，存储到存储器

![image-20220819155121918](D:\Codes\study-notes\计算机基础.assets\image-20220819155121918.png)

操作码：

* 第 20 位 L 选择数据传输的方向，即指令是 load 还是 store；
* 第 21 位 W 决定了当前指令结束时，基址寄存器是否会被更新；
* 第 22 位 B 选择操作数的大小，并确定 ARM 是传送 32 位字，还是 8 位字节；
* 第 23 位 U 定义了有效地址的计算是加上还是减去偏移量；
* 第 24 位 P 位控制偏移量时在计算有效地址之前还是之后被加到基址寄存器上；
* 第 25 位 # 决定了偏移量是带可选移位的寄存器内容，还是 12 位常量。



巴科斯范式（BNF）定义为：

`LDR|STR{cond}{B} Rd, [Rn, offset]{!}` 或者 `LDR|STR{cond}{B} Rd, [Rn], offset` 



### ARM 寻址方式

ARM 的寻址方式，根据基础的三种寻址方式，有七种变形：

1. `MOV r0, #Q` ，立即数寻址

2. `MOV r0, r1` ，寄存器到寄存器

3. `LDR r0, [r1]` ，寄存器间接寻址，也叫做索引寻址

4. `LDR r0, [r1, #Q]` ，带偏移量的寄存器间接寻址，也叫前索引寻址

   `LDR r0, [r1, #Q]!` ，自动前索引寻址

   `LDR r0, [r1], #Q` ，自动后索引寻址

5. `LDR r0, [r1, r2]` ，带索引的寄存器间接寻址

6. `LDR r0, [PC, #offset]` ，程序计数器相对寻址



![image-20220819153139599](D:\Codes\study-notes\计算机基础.assets\image-20220819153139599.png)

根据最新发展，ARM 支持 9 种寻址方式了，但依然是三种基础寻址方式的变形。



### ARM 指令举例

32 位二进制字符串 01010111001000100100000100000110 表示一条 ARM 指令。可以将其拆分为：

![image-20220819164727853](D:\Codes\study-notes\计算机基础.assets\image-20220819164727853.png)



### ARM 对子程序的支持

子程序（也叫过程、函数，或者 Java 中的方法）是一个能够被调用和执行，然后返回到调用点的那条指令的代码段。当调用子程序时，可以在调用者和子程序之间传递参数。

典型的 CISC 处理器提供 BSR 指令调用字程序，例如 BSR Proc_A 调用子程序，处理器将调用代码中要执行的下一条指令保存到安全的地方，然后执行 Proc_A 子程序。在子程序的末尾，使用 RTS 返回指令，返回到子程序调用点的下一条指令。

CISC 处理器采用栈结构为子程序调用与返回提供硬件支持，RISC 处理器一般不会提供完全的硬件支持，而是将子程序处理留给程序员完成。



ARM 的 `分支并链接指令 BL`，例如 BL Sub_A，将跳转到子程序 Sub_A 指定的目标地址，但它同时它会将返回地址（即程序计数器 r15）复制保存到链接寄存器 r14，在子程序的末尾通过把 r14 中保存的返回地址传送到程序计数器中，即可返回主程序。

![image-20220822090729415](D:\Codes\study-notes\计算机基础.assets\image-20220822090729415.png)



因此，ARM 无需特殊的返回指令，仅需要简单地写成 `MOV r15, r14` 



### 子程序与栈

栈（Stack）是一种先进后出（LIFO）的队列。微处理器中的栈由栈指针指向存储器的栈顶来实现：当数据添加到栈里（入栈）时，栈指针向上（或向下）移动；当数据项从栈里移出（出栈）时，栈指针向下（或向上）移动。



栈至少有四种构建方法：

* 栈顶（top of stack, TOS）在上，向下生长，指针指向栈顶
* TOS 在上，向下生长，指针指向栈顶 + 1
* TOS 在下，向上生长，指针指向栈顶
* TOS 在下，向上生长，指针指向栈顶 - 1

一般使用 TOS 在下，向上生长，指针指向栈顶的栈模型。

ARM 用 4 个术语描述栈：

* FA：满上升 full arise
* EA：空上升 empty arise
* FD：满下降 full down，最常用
* ED：空下降 empty down

ARM 用上升和下降描述栈朝高地址或低地址生长，用满和空描述栈指针指向栈顶元素或栈顶之上的空元素。



在发生子程序调用时，主程序的返回地址会入栈，在子程序执行结束时，主程序的返回地址出栈，得以继续执行。在嵌套子程序时，对应的返回地址会逐一入栈，由此可实现嵌套子程序，唯一的限制是内存空间的大小。

栈不仅可以用于管理子程序的返回地址，也备用来管理与子程序之间的参数传递。



### ARM 的大小端格式

存储器的字节编号是通用的，所有计算机都把存储器的第一个字节编号为 0，最后一个字节编号为 $2^n-1$ 。

然而处理器之间的位编号是不同的，绝大多数处理器（例如 ARM、Intel）都采用同样的方法，从字的最低位，到最高位。而有些处理器（例如 PowerPC）则与这个方案相反。

![image-20220822101104022](D:\Codes\study-notes\计算机基础.assets\image-20220822101104022.png)

将字数据的最高字节放在地址最低的存储单元，这种顺序叫做大端模式（big endian），绝大多数处理器都是大端模式；小端模式则刚好相反，将最低字节放在地址最低的存储单元中。

不同的端处理模式会影响程序员和设计师对程序的理解，同时也会影响多处理器的数据传输。



ARM 既支持大端模式，也支持小端模式，一般我们用大端模式举例。

ARM 存储器是按照字节编址的，连续的两个 32 位字节指令相差 4 字节，数据必须按照 4 字节边界对齐存放。任何时候 ARM 从存储器中取出一条指令，地址的低两位总是零，它能确保指令的边界是对齐的。

![image-20220822101837118](D:\Codes\study-notes\计算机基础.assets\image-20220822101837118.png)



### 块移动指令

有些 CISC 处理器能在寄存器组和存储器之间拷贝块数据。ARM 也有将块移动到存储器的指令 STM 与从存储器移出块的指令 LDM，它们能够在寄存器组和存储器之间拷贝块。这两条块移动指令用两个后缀描述了如何访问数据。

* LDM：将块数据从存储器加载到寄存器
* STM：将块数据从寄存器移出到存储器

![image-20220822104821940](D:\Codes\study-notes\计算机基础.assets\image-20220822104821940.png)



ARM 块移动指令最重要的应用之一是在进入子程序时保存寄存器，和从子程序返回时恢复寄存器。

块加载和块读取的后缀（指针的变化），这将取决于栈的类型：

* IA：后递增 increase after
* IB：前递增 increase before
* DA：后递减 decrease after
* DB：前递减 decrease before

### 软中断指令

ARM 提供软中断指令 SVC。

执行 SVC 会把返回地址保存到 r14_svc 中，把 CPSR 保存到 CPSR_svc，然后进入管理模式（supervisor mode），禁止中断请求，并强制跳转到存储器地址 $08_{16}$ 处。中断处理程序必须确保能在异常处理末尾正确恢复程序计数器和条件码。

## 数据存储

高级语言程序员用变量代表抽象数据单元的数据元素，这些数据单元是抽象的，因为它可以保存程序员定义的任意类型的数据元素，例如一个字节、一个数组或一个记录。

对于程序员来说，抽象数据单元具有一个真实存储单元的全部属性：可以从中读也可以向其中写。程序员可以给一个变量命名，将变量名与其存储位置关联在一起的过程被称作 `绑定` 。

变量还有一个与它相关的作用域。变量的作用域定义了它在程序内可见或可访问的范围。例如，一个在某过程中声明的变量在该过程内是可见的，但在该过程外是不可见的。

每个变量都有生命周期。为变量分配名字并为它们保留存储空间即可声明变量。从汇编语言程序员的视角来看，变量的存在始于它们被载入存储器，止于程序结束。

在运行时为变量分配存储空间的过程叫做 `动态分配` ，这是 Java 等语言的一个重要特征。有些语言，比如 COBOL 和 FORTRAN 采用 `静态分配` ，且所有绑定操作









# 操作系统

计算机系统由硬件和软件组成：

* 硬件：计算机系统中由电子、机械、电气、光学和磁学等元器件构成的各种部位和设备。CPU、存储器等都是硬件。
* 软件：完成一定任务的程序及其数据。包括系统软件和应用软件。
  * 系统软件：操作系统、编译程序、编辑程序、数据库管理系统等；
  * 应用软件：为各种应用目的而编制的程序。



计算机的硬件基本组成包括：

* 运算器：对数据进行算数运算和逻辑运算
* 存储器：存储二进制信息
* 控制器：按程序要求控制各功能部件协调一致工作
* 输入设备：将用户信息转为计算机能识别的二进制信息
* 输出设备：将计算机中的二进制信息转为用户可识别的信息



操作系统是一组控制和管理计算机硬件和软件资源，合理地组织计算机工作流程，以及方便用户的程序的集合。计算机管理的硬件资源包括：

* 处理器
* 存储器
* I/O 设备
* 文件



最基本的操作系统类型有三种：

* 批处理操作系统

  作业：是用户在一次解题或一个事务处理过程中要求计算机系统所做工作的集合，包括用户程序、所需的数据及命令等。

* 分时操作系统

  分时技术：把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。

  若某个作业在分配的时间片内不能完成其计算，则该作业暂停运行，把处理器让给另一个作业使用，等待下一轮再继续其运行。

* 实时操作系统

  系统能及时响应外部事件的请求，在规定的事件范围内完成对该事件的处理，并控制实时任务协调一致地运行。

* 通用操作系统

  兼具批处理操作系统、分时操作系统、实时操作系统特性的操作系统。

* 嵌入式操作系统

  对整个智能芯片及其所控制的各种部件模块等资源进行统一调度、指挥和控制的系统软件。

  嵌入式系统几乎包括了生活中的所有电器设备，例如微波炉、自动售货机、数字相机、工业仪表等。

* 个人计算机操作系统

  计算机在某一时间段内为单个用户服务，采用图形界面人机交互的工作方式，界面友好，使用方便。

* 网络操作系统

  基于计算机网络的，在各种计算机操作系统上按网络体系结构协议标准开发的软件。

  包括网络管理、通信、资源共享、系统安全和各种网络应用服务，其目标是互相通信及资源共享。

* 分布式操作系统

  将分散的处理单元经过网络连接形成的系统。其中每一个处理单元既具有高度自治性，又相互协同，能在系统范围内实现资源管理、任务动态分配，并能并行地运行分布式程序。



操作系统的基本特征：

* 并发：

  指两个或多个事件在同一事件间隔内发生。

  在多道程序环境下，并发是指宏观上一段时间内有多道程序在同时运行，但在单处理器系统中，微观上这些程序是交替执行的。

* 共享：

  指系统中的资源可供多个并发执行的进程共同使用。

  互斥共享：一段时间内只允许一个进程访问

  同时共享：一段时间内允许多个进程访问

* 虚拟：

  指把一个物理上的实体变为多个逻辑上的对应物。

* 不确定：

  表现为多个作业的执行顺序和每个作业的执行时间是不确定的，也称为异步性。



处理器管理的主要任务是管理处理器的分配和运行：

* 进程控制：负责进程的创建、撤销及状态转换
* 进程同步：对并发执行的进程进行协调，有同步和互斥
* 进程通信：负责完成进程间的信息交换
* 调度：作业调度和进程调度
  * 作业调度：从后备作业队列中按照一定的原则，选择若干作业进入内存
  * 进程调度：决定哪个进程获得处理器

存储器管理的主要任务是方便用户使用存储器、提高存储器利用率，从逻辑上扩充内存。

* 内存分配：按一定的策略为每道程序分配内存，程序运行结束后回收内存。分为静态和动态两种：
  * 静态：作业的内存空间在装入时确定，作业装入内存后不允许再申请新的内存空间，也不能在内存中移动
  * 动态：作业的基本内存空间在装入时确定，允许作业运行期间继续申请新的附件内存空间，允许作业在内存中移动
* 内存保护：保证各程序在自己的内存区域内运行而不相互干扰。简单的内存保护机制有：上下界寄存器
* 地址映射：将逻辑地址转换为物理地址。又称地址变换
  * 逻辑地址：用户编程时所使用的地址。又称相对地址、虚地址
  * 物理地址：内存中的地址。又称绝对地址、实地址
  * 地址空间：虚拟地址的集合
  * 内存空间：物理地址的集合
* 内存扩充：借助虚拟存储技术从逻辑上扩充内存，通过请求调入和置换功能可以实现虚拟内存

设备管理功能的主要任务是：

* 设备分配：根据用户的 I/O 请求，为之分配所需的设备，设备使用完成后还应回收
* 缓冲管理：对各类设备缓冲区进行有效管理
* 设备驱动：完成设备启动、I/O 操作及终端处理
* 设备独立性：用户程序中的设备与实际使用的物理设备无关。又称设备无关性

文件管理功能的主要任务是对文件进行管理，方便用户使用并保证文件安全性：

* 文件存储空间的管理：对文件存储空间进行管理，包括存储空间的分配和回收等功能
* 目录管理：管理文件的数据结构，提供按名存取的功能
* 文件操作管理：从外存读入数据或将数据写入外存
* 文件保护：防止未授权用户存取文件，防止授权用户以不正确方式存取文件



操作系统提供的公共和基础服务：

* 程序执行：把程序装入内存并运行
* 输入/输出操作：系统统一管理设备，为用户的程序运行提供 I/O 服务
* 文件系统管理：提供文件读写等服务
* 通信服务：提供进程间通信服务
* 错误检测及报告：能对用户程序运行过程中出现的错误进行检测，并及时报告给操作员或用户
* 资源分配：为进程的运行分配资源
* 统计：统计用户使用资源的类型和数量
* 保护：对计算机中存储的信息进行保护



操作系统向用户提供了各种使用其服务功能的手段，即提供了操作系统接口：

* 命令接口：

  * 脱机控制方式：用户将对作业的控制要求以作业控制说明书的方式提交给系统，由系统按照作业说明书的规定控制作业的执行
  * 联机控制方式：用户利用系统提供的一组键盘命令或其他操作命令和系统会话，交互式地控制程序的执行

* 程序接口：

  程序接口由一组系统调用命令组成，用户通过在程序中使用这些系统调用命令来请求操作系统提供的服务

* 图形接口：

  图形接口通过对屏幕上的对象直接进行操作，以控制和操纵程序的运行。图形接口减少或免除了用户的记忆工作量，其操作方式从原来的“记忆并键入”改为“选择并点取”，极大地方便了用户

  目前图形接口最为常见的是人机接口形式，可以认为图形接口时命令接口的图形化



系统调用由若干条指令构成的过程，用以实现特定的操作系统服务功能。系统调用命令有时也称为广义指令，它是由操作系统提供的一个或多个子程序模块实现的。

系统调用按功能可以分为：

* 设备管理：完成设备的请求或释放、以及设备启动等功能
* 文件管理：完成文件的读、写、创建及删除等功能
* 进程控制：完成进程的创建、撤销、阻塞及唤醒等功能
* 进程通信：完成进程间的消息传递或信号传递等功能
* 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能



系统调用的执行过程：

* 为执行系统调用命令做准备：主要工作是保留现场，并把系统调用命令的参数放入指定的存储单元
* 执行系统调用：根据系统调用命令的编号，找到相应子程序的入口地址，然后执行
* 执行后的处理：主要工作是恢复现场，并把系统调用的返回参数送入指定的存储单元



系统调用和过程调用的区别：

* 运行状态不同：系统调用在核心态下运行；子程序在用户态下运行
* 进入方式不同：系统调用通过中断机制进入以实现运行状态的改变；子程序直接调用不涉及运行状态的改变



现代操作系统运行的硬件环境包括：

* 处理器
* 存储器
* 设备
* 时钟
* 中断等



操作系统是一个大型系统软件，其内核主要有三种：

* 模块结构：将操作系统内核按照功能划分为独立的模块，每个模块实现一个完整独立的功能，模块之间只能通过事先规定好的接口方式来调用，共同构成一个完整的系统内核
* 层次结构：将操作系统内核按照一定的规则划分为一系列相互依赖的层次，每个参差可以分解为一系列更小的模块，每个模块完成一个特定的功能，并且只能与相邻的层次发生直接联系，所有这些层次共同构成一个完整的系统内核
* 微内核结构：将操作系统内核中的内存管理、设备管理、文件管理等高级服务功能尽可能地分离出来，变成几个独立的非内核模块，而在内核只保留少数基本的功能，例如调度、进程间通信、地址空间支持等，使内核变得简洁可靠



操作系统内核按照运行情况可以分为：

* 宏内核：也称单内核，在运行过程中，它是一个独立的进程。模块结构、层次结构的系统内核基本都是宏内核，Linux 系统属于宏内核类型
* 微内核：微内核中，大部分内核谋爱都作为独立的进程，它们之间通过消息通信，模块之间互相提供服务。微内核本身类似于一个消息管理器，通过合理组织内核来保证，只调入最需要的模块运行，Windows 2000 系统属于微内核类型



安全操作系统：是指对所管理的数据与资源提供适当的保护级，有效地控制硬件与软件功能的操作系统。

美国国防部于 1983 年推出了历史上第一个计算机安全评价标准《可信计算机系统评测准则（Trusted Computer System Evaluation Criteria, TCSEC）》，又称橘皮书：

* D 级：最低安全性
* C1 级：自主存取控制
* C2 级：较完善的自主存取控制（DAC）、审计
* B1 级：强制存取控制（MAC）
* B2 级：良好的结构化设计、形式化安全模型
* B3 级：全面的访问控制、可信恢复
* A1 级：形式化认证

通常称 B1 级以上的操作系统为安全操作系统。



# 虚拟化

通过虚拟化技术是将一台计算机虚拟为多台逻辑计算机，每台逻辑计算机可以运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。

“虚拟化是以某种用户和应用程序都可以很容易从中获益的方式来表示计算机资源的过程，而不是根据这些资源的实现、地理位置或物理包装的专有方式来表示它们。换句话说，它为数据、计算能力、存储资源以及其他资源提供了一个逻辑视图，而不是物理视图。”——Jonathan Eunice， Illuminata Inc

“虚拟化是标识计算机资源的逻辑组（或子集）的过程，这样就可以用从原始配置中获益的方式访问它们。这种资源的新虚拟视图并不受实现、物理位置或底层资源的物理配置的限制。”——Wikipedia

“虚拟化：对一组类似资源提供一个通用的抽象接口集，从而隐藏属性和操作之间的差异，并允许通过一种通用的方式来查看并维护资源。”——Open Grid Services Architecture Glossary of Terms



虚拟化的主要目的是对 IT 基础设施进行简化，它可以简化对资源以及对资源管理的访问。

* 完全虚拟化（Full-virtualization）
* 准虚拟化（Para-virtualization）
* 系统虚拟化



完全虚拟：

* 最流行的虚拟化方法使用 hypervisor 的软件，在虚拟服务器和底层硬件之间建立一个抽象层。VMware、微软的 VirtualPC 和 IBM 的 Z/VM 是代表该方法的三个商用产品，而基于核心的虚拟机 KVM 是面向 Linux 的开源产品
* hypervisor 可以捕获 CPU 指令，未指令访问硬件控制器和外设充当中介。因此，完全虚拟化技术几乎能让任何一款操作系统不用改动就能安装到虚拟服务器上，而它们不知道自己运行在虚拟化环境下。主要缺点是 hypervisor 给处理器带来的开销
* 在完全虚拟化的环境下，hypervisor 运行在裸硬件上，充当主机操作系统；而由 hypervisor 管理的虚拟服务器运行客户端操作系统（guest OS）

准虚拟：

* 完全虚拟化是处理器密集型技术，因为它要求 hypervisor 管理各个虚拟服务器，并让它们彼此独立。减轻这种负担的一种方法就是，改动客户端操作系统，让它以为自己运行在虚拟环境下，能够与 hypervisor 协同工作。这种方法就叫做准虚拟化（para-virtualization）
* Xen 是开源准虚拟化的一个例子。操作系统作为虚拟服务器在 Xen hypervisor 上运行之前，它必须在核心层面进行某些改变，因此，Xen 适用于 BSD、Linux、Solaris 及其他开源操作系统，但不适合对像 Windows 这些专有的操作系统进行虚拟化处理，因为它们无法改动
* 准虚拟化技术的优点是性能高，经过准虚拟化处理的服务器可与 hypervisor 协同工作，其响应能力几乎不亚于未经虚拟化处理的服务器。准虚拟化与完全虚拟化相比优点明显，以至于 VMware 和微软都在开发这项技术，以完善各自的产品

系统虚拟：

* 实现虚拟化还有一个方法，那就是在操作系统层面添加虚拟服务器功能。Slaris Container 就是这方面的一个例子，Virtuozzo/OpenVZ 是面向 Linux 的软件方案
* 就操作系统层的虚拟化而言，没有独立的 hypervisor 层，相反，主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。一个明显的区别是，如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统（每个实例有各自的应用程序和用户账户）
* 虽然操作系统层虚拟化的灵活性比较差，但本机速度性能比较高。此外，由于架构在所有虚拟服务器上使用单一、标准的操作系统，管理起来比异构环境要容易



# 习题

1. 专用计算机和通用计算机有什么区别？

   通用计算机：接收并处理输入信息、产生输出结果的可编程数字计算机。

2. 
